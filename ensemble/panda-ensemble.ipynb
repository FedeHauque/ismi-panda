{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\n\nimport sys\n\nimport gc\nimport os\nimport random\nimport time\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\n\nimport skimage.io\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nimport matplotlib.pyplot as plt\nimport gc\n\nimport sklearn.metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom functools import partial\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip\nfrom albumentations.pytorch import ToTensorV2\nfrom panda_common import TestDataset, CFG, CustomSEResNeXt, OptimizedRounder, PANDADataset, load_models, get_transforms, tile, get_tiles\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"_uuid":"4a03db48-1774-4d12-bca8-1b825e517104","_cell_guid":"e492316f-4923-4d04-b2ce-f593098a4fc1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-06-02T12:29:05.853053Z","iopub.execute_input":"2023-06-02T12:29:05.853313Z","iopub.status.idle":"2023-06-02T12:29:12.057851Z","shell.execute_reply.started":"2023-06-02T12:29:05.853289Z","shell.execute_reply":"2023-06-02T12:29:12.056894Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"data_dir = '/kaggle/input/prostate-cancer-grade-assessment'\nimage_folder = os.path.join(data_dir, 'test_images')\nis_test = os.path.exists(image_folder)  # IF test_images is not exists, we will use some train images.\n\n#Loading data\nif is_test:\n    test = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\nelse: \n    train = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv')\nsample = pd.read_csv('../input/prostate-cancer-grade-assessment/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:29:12.061323Z","iopub.execute_input":"2023-06-02T12:29:12.061614Z","iopub.status.idle":"2023-06-02T12:29:12.103791Z","shell.execute_reply.started":"2023-06-02T12:29:12.061586Z","shell.execute_reply":"2023-06-02T12:29:12.102916Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Inference - ResNext**","metadata":{}},{"cell_type":"code","source":"PATH_INFERENCE = '/kaggle/input/resnet-1epoch-baseline/'\n\ndef inference(model, samples, dir_name, device):\n    model.to(device) \n    probs = []\n    transform = get_transforms(data='valid')\n    for index, row in samples.iterrows():\n        file_name = row['image_id']\n        file_path = f'../input/prostate-cancer-grade-assessment/{dir_name}/{file_name}.tiff'\n        image = skimage.io.MultiImage(file_path)[0]\n        image = tile(image, sz=128, N=16)\n        #Tile concatenation\n        image = cv2.hconcat([cv2.vconcat([image[0], image[1], image[2], image[3]]), \n                             cv2.vconcat([image[4], image[5], image[6], image[7]]), \n                             cv2.vconcat([image[8], image[9], image[10], image[11]]), \n                             cv2.vconcat([image[12], image[13], image[14], image[15]])])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        #Test augmentations\n        if transform:\n            augmented = transform(image=image)\n            image = augmented['image']\n        image = image.to(device)\n        with torch.no_grad():\n            image = image[None,:]\n            y_preds = model(image)\n        del image\n        probs.append(y_preds.to('cpu').numpy())\n        del y_preds\n    probs = np.concatenate(probs)\n    gc.collect()\n    return probs","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:29:12.105193Z","iopub.execute_input":"2023-06-02T12:29:12.105551Z","iopub.status.idle":"2023-06-02T12:29:12.116337Z","shell.execute_reply.started":"2023-06-02T12:29:12.105522Z","shell.execute_reply":"2023-06-02T12:29:12.115469Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def submit(sample, coefficients, dir_name='test_images'):\n    probs = np.zeros(len(sample.index))\n    if os.path.exists(f'/kaggle/input/prostate-cancer-grade-assessment/{dir_name}'):\n        probs = []\n        for fold in tqdm(range(CFG.n_fold)):\n            model = CustomSEResNeXt(model_name='se_resnext50_32x4d')\n            weights_path = f'{PATH_INFERENCE}fold{fold}_se_resnext50.pth'\n            #Load the pre-trained weights\n            model.load_state_dict(torch.load(weights_path, map_location=device))\n            _probs = inference(model, sample, dir_name, device)\n            probs.append(_probs)\n            del model\n            gc.collect()\n        probs = np.mean(probs, axis=0)\n    return probs","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:29:12.119175Z","iopub.execute_input":"2023-06-02T12:29:12.119872Z","iopub.status.idle":"2023-06-02T12:29:12.127504Z","shell.execute_reply.started":"2023-06-02T12:29:12.119836Z","shell.execute_reply":"2023-06-02T12:29:12.126607Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# ResNeXt50, coefficients for a 10 epochs training on 100% of the data \ncoefficients = [0.55088115, 1.45590427, 2.41572283, 3.43710686, 4.19867511]\ndir_name = 'test_images' if is_test else 'train_images'\nsamples = sample if is_test else train.iloc[:3]\n\nresults = submit(samples, coefficients, dir_name)\nif len(results.shape) > 1:\n    results = [ r[0] for r in results ]","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:29:12.128925Z","iopub.execute_input":"2023-06-02T12:29:12.129254Z","iopub.status.idle":"2023-06-02T12:30:22.618584Z","shell.execute_reply.started":"2023-06-02T12:29:12.129221Z","shell.execute_reply":"2023-06-02T12:30:22.617627Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 4/4 [01:10<00:00, 17.62s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"results_resnext = []\n#Compute predictions according to coefficients\nfor i, pred in enumerate(results):\n    if pred < coefficients[0]:\n        results_resnext.append(pred / coefficients[0])\n    elif pred >= coefficients[0] and pred < coefficients[1]:\n        results_resnext.append(0.5 + (pred - coefficients[0]) / (coefficients[1] - coefficients[0]))\n    elif pred >= coefficients[1] and pred < coefficients[2]:\n        results_resnext.append(1.5 + (pred - coefficients[1]) / (coefficients[2] - coefficients[1]))\n    elif pred >= coefficients[2] and pred < coefficients[3]:\n        results_resnext.append(2.5 + (pred - coefficients[2]) / (coefficients[3] - coefficients[2]))\n    elif pred >= coefficients[3] and pred < coefficients[4]:\n        results_resnext.append(3.5 + (pred - coefficients[3]) / (coefficients[4] - coefficients[3]))\n    else:\n        results_resnext.append(4.5 + (pred - coefficients[4]) / (6 - coefficients[4]))\nresults_resnext = np.array(results_resnext)\nprint(results_resnext)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.620004Z","iopub.execute_input":"2023-06-02T12:30:22.621836Z","iopub.status.idle":"2023-06-02T12:30:22.633505Z","shell.execute_reply.started":"2023-06-02T12:30:22.621802Z","shell.execute_reply":"2023-06-02T12:30:22.632486Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[2.46206443 2.30262192 2.56141395]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Inference - EfficientNet**","metadata":{}},{"cell_type":"code","source":"model_dir = '/kaggle/input/first-exp'\nimage_folder = image_folder if is_test else os.path.join(data_dir, 'train_images')\n\ntile_size = 256\nimage_size = 256\nn_tiles = 36\nbatch_size = 2\nnum_workers = 4\n\nmodel_files = [\n    '/kaggle/input/first-exp/effnet_b0_best_fold0.pth'\n]\n\n#Load EfficientNet model.\nmodels = load_models(model_dir, model_files)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.634900Z","iopub.execute_input":"2023-06-02T12:30:22.635340Z","iopub.status.idle":"2023-06-02T12:30:23.121521Z","shell.execute_reply.started":"2023-06-02T12:30:22.635306Z","shell.execute_reply":"2023-06-02T12:30:23.120588Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/input/first-exp/effnet_b0_best_fold0.pth loaded!\n","output_type":"stream"}]},{"cell_type":"code","source":"def tt_augmentation(tiles):\n    idxes = list(range(n_tiles))\n\n    n_row_tiles = int(np.sqrt(n_tiles))\n    images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n    for h in range(n_row_tiles):\n        for w in range(n_row_tiles):\n            i = h * n_row_tiles + w\n\n            if len(tiles) > idxes[i]:\n                this_img = tiles[idxes[i]]['img']\n            else:\n                this_img = np.ones((image_size, image_size, 3)).astype(np.uint8) * 255\n            this_img = 255 - this_img\n            h1 = h * image_size\n            w1 = w * image_size\n            images[h1:h1+image_size, w1:w1+image_size] = this_img\n    \n    images = images.astype(np.float32)\n    images /= 255\n    images = images.transpose(2, 0, 1)\n    \n    return images","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:23.125702Z","iopub.execute_input":"2023-06-02T12:30:23.128153Z","iopub.status.idle":"2023-06-02T12:30:23.138901Z","shell.execute_reply.started":"2023-06-02T12:30:23.128121Z","shell.execute_reply":"2023-06-02T12:30:23.137950Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"LOGITS = []\ntile_mode = 0\nwith torch.no_grad():\n    for index, row in samples.iterrows():\n        file_name = row['image_id']\n        tiff_file = os.path.join(image_folder, f'{file_name}.tiff')\n        #Load image\n        image = skimage.io.MultiImage(tiff_file)[-1]\n        #Generate tiles\n        tiles, OK = get_tiles(image, tile_mode)\n        #Test time augmentation\n        image = torch.tensor(tt_augmentation(tiles))\n        image = image[None,:].to(device)\n        logits = models[0](image)\n        del image\n        LOGITS.append(logits)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:23.143838Z","iopub.execute_input":"2023-06-02T12:30:23.146370Z","iopub.status.idle":"2023-06-02T12:30:38.446399Z","shell.execute_reply.started":"2023-06-02T12:30:23.146339Z","shell.execute_reply":"2023-06-02T12:30:38.445502Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"LOGITS = torch.cat(LOGITS).sigmoid().cpu()\nPREDS = LOGITS.sum(1).round().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:38.449557Z","iopub.execute_input":"2023-06-02T12:30:38.449919Z","iopub.status.idle":"2023-06-02T12:30:38.490382Z","shell.execute_reply.started":"2023-06-02T12:30:38.449885Z","shell.execute_reply":"2023-06-02T12:30:38.489481Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pred_effnet = LOGITS.sum(1)\n\n#Average results of both models.\nensemble_preds = torch.round((pred_effnet + results_resnext) / 2).numpy().astype(int)\nsample = pd.read_csv('../input/prostate-cancer-grade-assessment/sample_submission.csv')\nsample['isup_grade'] = ensemble_preds\n#Save submission file\nsample[['image_id', 'isup_grade']].to_csv('submission.csv', index=False)\ndisplay(sample)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:38.491891Z","iopub.execute_input":"2023-06-02T12:30:38.492250Z","iopub.status.idle":"2023-06-02T12:30:38.529507Z","shell.execute_reply.started":"2023-06-02T12:30:38.492218Z","shell.execute_reply":"2023-06-02T12:30:38.528619Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"                           image_id  isup_grade\n0  005700be7e06878e6605e7a5a39de1b2           3\n1  005c6e8877caf724c600fdce5d417d40           3\n2  0104f76634ff89bfff1ef0804a95c380           3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>isup_grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005c6e8877caf724c600fdce5d417d40</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0104f76634ff89bfff1ef0804a95c380</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}