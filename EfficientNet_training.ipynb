{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Downloading the learning rate scheduler\n!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:13.960945Z","iopub.execute_input":"2023-06-02T12:30:13.961302Z","iopub.status.idle":"2023-06-02T12:30:22.138411Z","shell.execute_reply.started":"2023-06-02T12:30:13.961271Z","shell.execute_reply":"2023-06-02T12:30:22.137493Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n  Cloning https://github.com/ildoonet/pytorch-gradual-warmup-lr.git to /tmp/pip-req-build-x17oa_1h\n  Running command git clone -q https://github.com/ildoonet/pytorch-gradual-warmup-lr.git /tmp/pip-req-build-x17oa_1h\nRequirement already satisfied (use --upgrade to upgrade): warmup-scheduler==0.3.2 from git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git in /opt/conda/lib/python3.7/site-packages\nBuilding wheels for collected packages: warmup-scheduler\n  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3.2-py3-none-any.whl size=3881 sha256=bf553d519899850fc9c0beb86f7dce4cd3dc09d835000f7e11542db5d20d3d8f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-u8l7bfeh/wheels/bf/81/52/0e3bc0b645a339f94c76b4dcb8c8b7a5f588a614f5add83b9f\nSuccessfully built warmup-scheduler\n\u001b[33mWARNING: You are using pip version 20.1; however, version 23.1.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport sys\nsys.path = [\n    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n] + sys.path","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.140520Z","iopub.execute_input":"2023-06-02T12:30:22.140837Z","iopub.status.idle":"2023-06-02T12:30:22.149714Z","shell.execute_reply.started":"2023-06-02T12:30:22.140807Z","shell.execute_reply":"2023-06-02T12:30:22.148810Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import time\nimport skimage.io\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport PIL.Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\nfrom warmup_scheduler import GradualWarmupScheduler\nfrom efficientnet_pytorch import model as enet\nimport albumentations\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import cohen_kappa_score\nfrom tqdm import tqdm_notebook as tqdm\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-02T12:30:22.153128Z","iopub.execute_input":"2023-06-02T12:30:22.153400Z","iopub.status.idle":"2023-06-02T12:30:22.164333Z","shell.execute_reply.started":"2023-06-02T12:30:22.153373Z","shell.execute_reply":"2023-06-02T12:30:22.163327Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"data_dir = '../input/prostate-cancer-grade-assessment'\ndf_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\nimage_folder = os.path.join(data_dir, 'train_images')\n\n# Model kernel\nkernel_type = 'effnet_b0'\nenet_type = 'efficientnet-b0'\n\n# Specify the folder which we want to train\nfold = 3\n\n# Parameters of the Concatenate Tiling Approach\ntile_size = 256\nimage_size = 256\nn_tiles = 36\n\n# Hyperparameters for training\nbatch_size = 2\nnum_workers = 4\nout_dim = 5\ninit_lr = 3e-4\nwarmup_factor = 10\naug_prob = 0.5\nwarmup_epo = 1\nn_epochs = 15\n\n# Load only part of the dataset for experiments\ndf_train = df_train.sample(3000, random_state = 42).reset_index(drop=True) #if DEBUG else df_train\n\ndevice = torch.device('cuda')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.165987Z","iopub.execute_input":"2023-06-02T12:30:22.166345Z","iopub.status.idle":"2023-06-02T12:30:22.201581Z","shell.execute_reply.started":"2023-06-02T12:30:22.166306Z","shell.execute_reply":"2023-06-02T12:30:22.200742Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# Keeping track of the experiments in Weights&Biases\n\n!pip install wandb\nimport wandb\nwandb.login()\nrun = wandb.init(\n    # Set the project where this run will be logged\n    project=\"ismi\",\n    # Track hyperparameters and run metadata\n    config={\n        \"model\": kernel_type,\n        \"learning_rate\": init_lr,\n        \"epochs\": n_epochs,\n        \"batch_size\": batch_size,\n        \"fold\": fold,\n        \"aug_prob\": aug_prob\n    })\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.204795Z","iopub.execute_input":"2023-06-02T12:30:22.205199Z","iopub.status.idle":"2023-06-02T12:30:22.212607Z","shell.execute_reply.started":"2023-06-02T12:30:22.205159Z","shell.execute_reply":"2023-06-02T12:30:22.211736Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'\\n# Keeping track of the experiments in Weights&Biases\\n\\n!pip install wandb\\nimport wandb\\nwandb.login()\\nrun = wandb.init(\\n    # Set the project where this run will be logged\\n    project=\"ismi\",\\n    # Track hyperparameters and run metadata\\n    config={\\n        \"model\": kernel_type,\\n        \"learning_rate\": init_lr,\\n        \"epochs\": n_epochs,\\n        \"batch_size\": batch_size,\\n        \"fold\": fold,\\n        \"aug_prob\": aug_prob\\n    })\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create Folds","metadata":{}},{"cell_type":"code","source":"# Define folds for the StratifiedKFold \nskf = StratifiedKFold(5, shuffle=True, random_state=42)\ndf_train['fold'] = -1\n\nfor i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['isup_grade'])):\n    df_train.loc[valid_idx, 'fold'] = i\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.214105Z","iopub.execute_input":"2023-06-02T12:30:22.214628Z","iopub.status.idle":"2023-06-02T12:30:22.253413Z","shell.execute_reply.started":"2023-06-02T12:30:22.214590Z","shell.execute_reply":"2023-06-02T12:30:22.252637Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                           image_id data_provider  isup_grade gleason_score  \\\n0  e8baa3bb9dcfb9cef5ca599d62bb8046    karolinska           4           4+4   \n1  9b2948ff81b64677a1a152a1532c1a50    karolinska           2           3+4   \n2  5b003d43ec0ce5979062442486f84cf7       radboud           4           5+3   \n3  375b2c9501320b35ceb638a3274812aa       radboud           1           3+3   \n4  e4e49a91640feea58d109aff11df4197    karolinska           1           3+3   \n\n   fold  \n0     2  \n1     4  \n2     0  \n3     3  \n4     3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n      <th>isup_grade</th>\n      <th>gleason_score</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e8baa3bb9dcfb9cef5ca599d62bb8046</td>\n      <td>karolinska</td>\n      <td>4</td>\n      <td>4+4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9b2948ff81b64677a1a152a1532c1a50</td>\n      <td>karolinska</td>\n      <td>2</td>\n      <td>3+4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5b003d43ec0ce5979062442486f84cf7</td>\n      <td>radboud</td>\n      <td>4</td>\n      <td>5+3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>375b2c9501320b35ceb638a3274812aa</td>\n      <td>radboud</td>\n      <td>1</td>\n      <td>3+3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e4e49a91640feea58d109aff11df4197</td>\n      <td>karolinska</td>\n      <td>1</td>\n      <td>3+3</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# Load the pretrained EfficientNet\n\npretrained_model = {\n    'efficientnet-b0': '/kaggle/input/efficientnet-pytorch/efficientnet-b0-08094119.pth'\n}","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.255666Z","iopub.execute_input":"2023-06-02T12:30:22.256255Z","iopub.status.idle":"2023-06-02T12:30:22.260299Z","shell.execute_reply.started":"2023-06-02T12:30:22.256217Z","shell.execute_reply":"2023-06-02T12:30:22.259454Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class enetv2(nn.Module):\n    # EfficientNet model\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.261609Z","iopub.execute_input":"2023-06-02T12:30:22.263035Z","iopub.status.idle":"2023-06-02T12:30:22.272777Z","shell.execute_reply.started":"2023-06-02T12:30:22.262995Z","shell.execute_reply":"2023-06-02T12:30:22.271826Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"def get_tiles(img, mode=0):\n        # Implementation of the concatenate tile pooling approach\n        result = []\n        h, w, c = img.shape\n        pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n        pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n\n        img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n        img3 = img2.reshape(\n            img2.shape[0] // tile_size,\n            tile_size,\n            img2.shape[1] // tile_size,\n            tile_size,\n            3\n        )\n\n        img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n        n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n        if len(img3) < n_tiles:\n            img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n        idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n        img3 = img3[idxs]\n        for i in range(len(img3)):\n            result.append({'img':img3[i], 'idx':i})\n        return result, n_tiles_with_info >= n_tiles\n\n\nclass PANDADataset(Dataset):\n    def __init__(self,\n                 df,\n                 image_size,\n                 n_tiles=n_tiles,\n                 tile_mode=0,\n                 rand=False,\n                 transform=None,\n                ):\n\n        self.df = df.reset_index(drop=True)\n        self.image_size = image_size\n        self.n_tiles = n_tiles\n        self.tile_mode = tile_mode\n        self.rand = rand\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        img_id = row.image_id\n        \n        tiff_file = os.path.join(image_folder, f'{img_id}.tiff')\n        # extract median resolution, Change number in brackets to extract higher or lower resolution\n        image = skimage.io.MultiImage(tiff_file)[1]\n        tiles, OK = get_tiles(image, self.tile_mode)\n\n        if self.rand:\n            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n        else:\n            idxes = list(range(self.n_tiles))\n\n        n_row_tiles = int(np.sqrt(self.n_tiles))\n        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n        for h in range(n_row_tiles):\n            for w in range(n_row_tiles):\n                i = h * n_row_tiles + w\n    \n                if len(tiles) > idxes[i]:\n                    this_img = tiles[idxes[i]]['img']\n                else:\n                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n                this_img = 255 - this_img\n                if self.transform is not None:\n                    this_img = self.transform(image=this_img)['image']\n                h1 = h * image_size\n                w1 = w * image_size\n                images[h1:h1+image_size, w1:w1+image_size] = this_img\n\n        if self.transform is not None:\n            images = self.transform(image=images)['image']\n        images = images.astype(np.float32)\n        images /= 255\n        images = images.transpose(2, 0, 1)\n\n        label = np.zeros(5).astype(np.float32)\n        label[:row.isup_grade] = 1.\n        return torch.tensor(images), torch.tensor(label)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.274217Z","iopub.execute_input":"2023-06-02T12:30:22.274636Z","iopub.status.idle":"2023-06-02T12:30:22.307623Z","shell.execute_reply.started":"2023-06-02T12:30:22.274598Z","shell.execute_reply":"2023-06-02T12:30:22.306634Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"# Defining data augmentation transformations\ntransforms_train = albumentations.Compose([\n    albumentations.Transpose(p=aug_prob),\n    albumentations.VerticalFlip(p=aug_prob),\n    albumentations.HorizontalFlip(p=aug_prob),\n])\ntransforms_val = albumentations.Compose([])","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.308957Z","iopub.execute_input":"2023-06-02T12:30:22.309382Z","iopub.status.idle":"2023-06-02T12:30:22.321859Z","shell.execute_reply.started":"2023-06-02T12:30:22.309344Z","shell.execute_reply":"2023-06-02T12:30:22.320944Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{}},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.323184Z","iopub.execute_input":"2023-06-02T12:30:22.323551Z","iopub.status.idle":"2023-06-02T12:30:22.331721Z","shell.execute_reply.started":"2023-06-02T12:30:22.323514Z","shell.execute_reply":"2023-06-02T12:30:22.331062Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Train & Val","metadata":{}},{"cell_type":"code","source":"def train_epoch(loader, optimizer):\n\n    model.train()\n    train_loss = []\n    bar = tqdm(loader)\n    for (data, target) in bar:\n        \n        data, target = data.to(device), target.to(device)\n        loss_func = criterion\n        optimizer.zero_grad()\n        logits = model(data)\n        loss = loss_func(logits, target)\n        loss.backward()\n        optimizer.step()\n\n        loss_np = loss.detach().cpu().numpy()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n        # Printing the training loss with W&B\n    #    wandb.log({'training loss': loss })\n    return train_loss\n\n\ndef val_epoch(loader, get_output=False):\n\n    model.eval()\n    val_loss = []\n    LOGITS = []\n    PREDS = []\n    TARGETS = []\n    best_score = -100\n\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            data, target = data.to(device), target.to(device)\n            logits = model(data)\n\n            loss = criterion(logits, target)\n\n            pred = logits.sigmoid().sum(1).detach().round()\n            LOGITS.append(logits)\n            PREDS.append(pred)\n            TARGETS.append(target.sum(1))\n\n            val_loss.append(loss.detach().cpu().numpy())\n        val_loss = np.mean(val_loss)\n\n    LOGITS = torch.cat(LOGITS).cpu().numpy()\n    PREDS = torch.cat(PREDS).cpu().numpy()\n    TARGETS = torch.cat(TARGETS).cpu().numpy()\n    acc = (PREDS == TARGETS).mean() * 100.\n    \n    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n    qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n    qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n    # Printing the validation metrics with W&B\n   # wandb.log({\"accuracy\": acc, \"loss\": val_loss, 'qwk': qwk})\n    print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n   \n    \n    if get_output:\n        return LOGITS\n    else:\n        return val_loss, acc, qwk\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:31:19.889315Z","iopub.execute_input":"2023-06-02T12:31:19.889690Z","iopub.status.idle":"2023-06-02T12:31:19.912137Z","shell.execute_reply.started":"2023-06-02T12:31:19.889653Z","shell.execute_reply":"2023-06-02T12:31:19.910982Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Create Dataloader & Model & Optimizer","metadata":{}},{"cell_type":"code","source":"train_idx = np.where((df_train['fold'] != fold))[0]\nvalid_idx = np.where((df_train['fold'] == fold))[0]\n\ndf_this  = df_train.loc[train_idx]\ndf_valid = df_train.loc[valid_idx]\n\ndataset_train = PANDADataset(df_this , image_size, n_tiles, transform=transforms_train)\ndataset_valid = PANDADataset(df_valid, image_size, n_tiles, transform=transforms_val)\n\ntrain_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n\nmodel = enetv2(enet_type, out_dim=out_dim)\n\n# Uncomment to load model from checkpoint\n# model.load_state_dict(torch.load(PATH))\nmodel = model.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)\nscheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)\nscheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n\nprint(len(dataset_train), len(dataset_valid))","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:30:22.358792Z","iopub.execute_input":"2023-06-02T12:30:22.359386Z","iopub.status.idle":"2023-06-02T12:30:26.481992Z","shell.execute_reply.started":"2023-06-02T12:30:22.359347Z","shell.execute_reply":"2023-06-02T12:30:26.481012Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"2400 600\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Run Training","metadata":{}},{"cell_type":"code","source":"qwk_max = 0.\nbest_file = f'{kernel_type}_best_fold{fold}.pth'\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n    scheduler.step(epoch-1)\n\n    train_loss = train_epoch(train_loader, optimizer)\n    val_loss, acc, qwk = val_epoch(valid_loader)\n\n    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, acc: {(acc):.5f}, qwk: {(qwk):.5f}'\n    print(content)\n    with open(f'log_{kernel_type}.txt', 'a') as appender:\n        appender.write(content + '\\n')\n\n    if qwk > qwk_max:\n        print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(qwk_max, qwk))\n        torch.save(model.state_dict(), best_file)\n        qwk_max = qwk\n        \n\ntorch.save(model.state_dict(), os.path.join(f'{kernel_type}_final_fold{fold}.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-06-02T12:31:26.755931Z","iopub.execute_input":"2023-06-02T12:31:26.756322Z","iopub.status.idle":"2023-06-02T12:31:36.695414Z","shell.execute_reply.started":"2023-06-02T12:31:26.756289Z","shell.execute_reply":"2023-06-02T12:31:36.693066Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Fri Jun  2 12:31:26 2023 Epoch: 1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \"\"\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1200.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da071f7bc7074b46aff4002862b6890b"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-6bc263ed131b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqwk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-e90771a1ed63>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(loader, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}