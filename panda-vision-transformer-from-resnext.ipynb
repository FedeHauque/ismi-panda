{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook","metadata":{}},{"cell_type":"markdown","source":"- PyTorch se_resnext50 regression starter code  \n- 4 folds \n- In this notebook, we treat 16 tiles as 1 image\n- Tile images are based on @iafoss's work, Thanks for sharing!\n- https://www.kaggle.com/iafoss/panda-16x128x128-tiles\n- https://www.kaggle.com/iafoss/panda-concat-tile-pooling-starter-0-79-lb\n- https://www.kaggle.com/iafoss/panda-concat-tile-pooling-starter-inference\n\nIf this notebook is helpful, feel free to upvote :)  ","metadata":{}},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    debug=False\n    #height=256\n    #width=256\n    lr=1e-4\n    batch_size=16\n    epochs=4 # you can train more epochs\n    seed=777\n    target_size=1\n    target_col='isup_grade'\n    n_fold=4\n    MODEL_PATH = (\"../input/vit-pytorch-pretrained-models/jx_vit_large_p32_384-9b920ba8.pth\")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:37.614056Z","iopub.execute_input":"2023-05-25T10:24:37.614351Z","iopub.status.idle":"2023-05-25T10:24:37.620383Z","shell.execute_reply.started":"2023-05-25T10:24:37.614301Z","shell.execute_reply":"2023-05-25T10:24:37.619252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = (\"../input/vit-pytorch-pretrained-models/jx_vit_large_p32_384-9b920ba8.pth\")\nprint(MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:37.643304Z","iopub.execute_input":"2023-05-25T10:24:37.643995Z","iopub.status.idle":"2023-05-25T10:24:37.649752Z","shell.execute_reply.started":"2023-05-25T10:24:37.643939Z","shell.execute_reply":"2023-05-25T10:24:37.648717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd ","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-05-25T10:24:37.651998Z","iopub.execute_input":"2023-05-25T10:24:37.652596Z","iopub.status.idle":"2023-05-25T10:24:37.657293Z","shell.execute_reply.started":"2023-05-25T10:24:37.652546Z","shell.execute_reply":"2023-05-25T10:24:37.656328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input/prostate-cancer-grade-assessment')","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:37.658855Z","iopub.execute_input":"2023-05-25T10:24:37.659653Z","iopub.status.idle":"2023-05-25T10:24:37.670846Z","shell.execute_reply.started":"2023-05-25T10:24:37.659579Z","shell.execute_reply":"2023-05-25T10:24:37.669755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv')\ntest = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\nsample = pd.read_csv('../input/prostate-cancer-grade-assessment/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:37.672101Z","iopub.execute_input":"2023-05-25T10:24:37.672639Z","iopub.status.idle":"2023-05-25T10:24:37.722317Z","shell.execute_reply.started":"2023-05-25T10:24:37.672570Z","shell.execute_reply":"2023-05-25T10:24:37.721484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:37.726447Z","iopub.execute_input":"2023-05-25T10:24:37.726763Z","iopub.status.idle":"2023-05-25T10:24:37.744489Z","shell.execute_reply.started":"2023-05-25T10:24:37.726715Z","shell.execute_reply":"2023-05-25T10:24:37.743801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:37.747728Z","iopub.execute_input":"2023-05-25T10:24:37.748043Z","iopub.status.idle":"2023-05-25T10:24:37.756732Z","shell.execute_reply.started":"2023-05-25T10:24:37.747991Z","shell.execute_reply":"2023-05-25T10:24:37.755697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:37.758194Z","iopub.execute_input":"2023-05-25T10:24:37.758786Z","iopub.status.idle":"2023-05-25T10:24:37.773964Z","shell.execute_reply.started":"2023-05-25T10:24:37.758735Z","shell.execute_reply":"2023-05-25T10:24:37.773161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['isup_grade'].hist()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:37.776779Z","iopub.execute_input":"2023-05-25T10:24:37.777422Z","iopub.status.idle":"2023-05-25T10:24:37.972661Z","shell.execute_reply.started":"2023-05-25T10:24:37.777369Z","shell.execute_reply":"2023-05-25T10:24:37.971721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\n\nimport sys\n\nimport gc\nimport os\nimport random\nimport time\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\n\nimport skimage.io\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\n\nimport sklearn.metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom functools import partial\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.models as models\n\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip, Resize\nfrom albumentations.pytorch import ToTensorV2\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:37.974234Z","iopub.execute_input":"2023-05-25T10:24:37.974686Z","iopub.status.idle":"2023-05-25T10:24:40.764348Z","shell.execute_reply.started":"2023-05-25T10:24:37.974622Z","shell.execute_reply":"2023-05-25T10:24:40.763579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append('../input/timm-pytorch-image-models')\nimport timm","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:40.765600Z","iopub.execute_input":"2023-05-25T10:24:40.766144Z","iopub.status.idle":"2023-05-25T10:24:41.889824Z","shell.execute_reply.started":"2023-05-25T10:24:40.766091Z","shell.execute_reply":"2023-05-25T10:24:41.888709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n    \ndef init_logger(log_file='train.log'):\n    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n    \n    log_format = '%(asctime)s %(levelname)s %(message)s'\n    \n    stream_handler = StreamHandler()\n    stream_handler.setLevel(DEBUG)\n    stream_handler.setFormatter(Formatter(log_format))\n    \n    file_handler = FileHandler(log_file)\n    file_handler.setFormatter(Formatter(log_format))\n    \n    logger = getLogger('PANDA')\n    logger.setLevel(DEBUG)\n    logger.addHandler(stream_handler)\n    logger.addHandler(file_handler)\n    \n    return logger\n\nLOG_FILE = 'train.log'\nLOGGER = init_logger(LOG_FILE)\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:41.891670Z","iopub.execute_input":"2023-05-25T10:24:41.892088Z","iopub.status.idle":"2023-05-25T10:24:41.909016Z","shell.execute_reply.started":"2023-05-25T10:24:41.892033Z","shell.execute_reply":"2023-05-25T10:24:41.907998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"def tile(img, sz=128, N=16):\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n                 constant_values=255)\n    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:41.910514Z","iopub.execute_input":"2023-05-25T10:24:41.911160Z","iopub.status.idle":"2023-05-25T10:24:41.923676Z","shell.execute_reply.started":"2023-05-25T10:24:41.910948Z","shell.execute_reply":"2023-05-25T10:24:41.922747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df, labels, transform=None):\n        self.df = df\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.df['image_id'].values[idx]\n        file_path = f'../input/prostate-cancer-grade-assessment/train_images/{file_name}.tiff'\n        image = skimage.io.MultiImage(file_path)[-1]\n        #image = tile(image, sz=128, N=16)\n        #image = cv2.hconcat([cv2.vconcat([image[0], image[1], image[2], image[3]]), \n        #                     cv2.vconcat([image[4], image[5], image[6], image[7]]), \n        #                     cv2.vconcat([image[8], image[9], image[10], image[11]]), \n        #                     cv2.vconcat([image[12], image[13], image[14], image[15]])])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n            \n        label = torch.tensor(self.labels[idx]).float()\n        \n        return image, label\n    \n\nclass TestDataset(Dataset):\n    def __init__(self, df, dir_name, transform=None):\n        self.df = df\n        self.dir_name = dir_name\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.df['image_id'].values[idx]\n        file_path = f'../input/prostate-cancer-grade-assessment/{self.dir_name}/{file_name}.tiff'\n        image = skimage.io.MultiImage(file_path)[-1]\n        #image = tile(image, sz=128, N=16)\n        #image = cv2.hconcat([cv2.vconcat([image[0], image[1], image[2], image[3]]), \n        #                     cv2.vconcat([image[4], image[5], image[6], image[7]]), \n        #                     cv2.vconcat([image[8], image[9], image[10], image[11]]), \n        #                     cv2.vconcat([image[12], image[13], image[14], image[15]])])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        \n        return image","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:41.928037Z","iopub.execute_input":"2023-05-25T10:24:41.928431Z","iopub.status.idle":"2023-05-25T10:24:41.943800Z","shell.execute_reply.started":"2023-05-25T10:24:41.928370Z","shell.execute_reply":"2023-05-25T10:24:41.942950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ntrain_dataset = TrainDataset(train, train[CFG.target_col], transform=None)\ntrain_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:41.947505Z","iopub.execute_input":"2023-05-25T10:24:41.947838Z","iopub.status.idle":"2023-05-25T10:24:41.955796Z","shell.execute_reply.started":"2023-05-25T10:24:41.947791Z","shell.execute_reply":"2023-05-25T10:24:41.955004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ni = 0\nfor image, label in train_loader:\n    plt.imshow(image[0])\n    plt.show()\n    i = i + 1\n    if i == 5:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:41.959042Z","iopub.execute_input":"2023-05-25T10:24:41.959337Z","iopub.status.idle":"2023-05-25T10:24:43.600447Z","shell.execute_reply.started":"2023-05-25T10:24:41.959286Z","shell.execute_reply":"2023-05-25T10:24:43.599354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforms","metadata":{}},{"cell_type":"code","source":"def get_transforms(*, data):\n    \n    assert data in ('train', 'valid')\n    \n    if data == 'train':\n        return Compose([\n            Resize(384,384),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n    \n    elif data == 'valid':\n        return Compose([\n            Resize(384,384),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:43.602146Z","iopub.execute_input":"2023-05-25T10:24:43.602827Z","iopub.status.idle":"2023-05-25T10:24:43.612682Z","shell.execute_reply.started":"2023-05-25T10:24:43.602764Z","shell.execute_reply":"2023-05-25T10:24:43.611718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train valid split","metadata":{}},{"cell_type":"code","source":"if CFG.debug:\n    folds = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True).copy()\nelse:\n    folds = train.copy()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:43.614095Z","iopub.execute_input":"2023-05-25T10:24:43.614730Z","iopub.status.idle":"2023-05-25T10:24:43.623931Z","shell.execute_reply.started":"2023-05-25T10:24:43.614627Z","shell.execute_reply":"2023-05-25T10:24:43.623185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = folds[CFG.target_col].values\nkf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor fold, (train_index, val_index) in enumerate(kf.split(folds.values, train_labels)):\n    folds.loc[val_index, 'fold'] = int(fold)\nfolds['fold'] = folds['fold'].astype(int)\nfolds.to_csv('folds.csv', index=None)\nfolds.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:43.626428Z","iopub.execute_input":"2023-05-25T10:24:43.626921Z","iopub.status.idle":"2023-05-25T10:24:43.891737Z","shell.execute_reply.started":"2023-05-25T10:24:43.626870Z","shell.execute_reply":"2023-05-25T10:24:43.890810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"print(\"Available Vision Transformer Models: \")\ntimm.list_models(\"vit*\")","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:43.892949Z","iopub.execute_input":"2023-05-25T10:24:43.893394Z","iopub.status.idle":"2023-05-25T10:24:43.901517Z","shell.execute_reply.started":"2023-05-25T10:24:43.893248Z","shell.execute_reply":"2023-05-25T10:24:43.900576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ViTBase16(nn.Module):\n    def __init__(self, n_classes, pretrained=False):\n\n        super(ViTBase16, self).__init__()\n\n        self.model = timm.create_model(\"vit_large_patch32_384\", pretrained=False)\n        if pretrained:\n            self.model.load_state_dict(torch.load(CFG.MODEL_PATH))\n\n        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n    def train_one_epoch(self, train_loader, criterion, optimizer, device):\n        # keep track of training loss\n        epoch_loss = 0.0\n        epoch_accuracy = 0.0\n\n        ###################\n        # train the model #\n        ###################\n        self.model.train()\n        for i, (data, target) in enumerate(train_loader):\n            # move tensors to GPU if CUDA is available\n            if device.type == \"cuda\":\n                data, target = data.cuda(), target.cuda()\n            elif device.type == \"xla\":\n                data = data.to(device, dtype=torch.float32)\n                target = target.to(device, dtype=torch.int64)\n\n            # clear the gradients of all optimized variables\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = self.forward(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # Calculate Accuracy\n            accuracy = (output.argmax(dim=1) == target).float().mean()\n            # update training loss and accuracy\n            epoch_loss += loss\n            epoch_accuracy += accuracy\n\n            # perform a single optimization step (parameter update)\n            if device.type == \"xla\":\n                xm.optimizer_step(optimizer)\n\n                if i % 20 == 0:\n                    xm.master_print(f\"\\tBATCH {i+1}/{len(train_loader)} - LOSS: {loss}\")\n\n            else:\n                optimizer.step()\n\n        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n\n    def validate_one_epoch(self, valid_loader, criterion, device):\n        # keep track of validation loss\n        valid_loss = 0.0\n        valid_accuracy = 0.0\n\n        ######################\n        # validate the model #\n        ######################\n        self.model.eval()\n        for data, target in valid_loader:\n            # move tensors to GPU if CUDA is available\n            if device.type == \"cuda\":\n                data, target = data.cuda(), target.cuda()\n            elif device.type == \"xla\":\n                data = data.to(device, dtype=torch.float32)\n                target = target.to(device, dtype=torch.int64)\n\n            with torch.no_grad():\n                # forward pass: compute predicted outputs by passing inputs to the model\n                output = self.model(data)\n                # calculate the batch loss\n                loss = criterion(output, target)\n                # Calculate Accuracy\n                accuracy = (output.argmax(dim=1) == target).float().mean()\n                # update average validation loss and accuracy\n                valid_loss += loss\n                valid_accuracy += accuracy\n\n        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:43.902932Z","iopub.execute_input":"2023-05-25T10:24:43.903511Z","iopub.status.idle":"2023-05-25T10:24:43.928380Z","shell.execute_reply.started":"2023-05-25T10:24:43.903461Z","shell.execute_reply":"2023-05-25T10:24:43.927334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\n\ndef quadratic_weighted_kappa(y_hat, y):\n    return cohen_kappa_score(y_hat, y, weights='quadratic')\n\n\nclass OptimizedRounder():\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            elif pred >= coef[3] and pred < coef[4]:\n                X_p[i] = 4\n            else:\n                X_p[i] = 5\n\n        ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            elif pred >= coef[3] and pred < coef[4]:\n                X_p[i] = 4\n            else:\n                X_p[i] = 5\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:43.931992Z","iopub.execute_input":"2023-05-25T10:24:43.932364Z","iopub.status.idle":"2023-05-25T10:24:43.952262Z","shell.execute_reply.started":"2023-05-25T10:24:43.932285Z","shell.execute_reply":"2023-05-25T10:24:43.951364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(fold):\n    \n    print(f\"### fold: {fold} ###\")\n    \n    optimized_rounder = OptimizedRounder()\n        \n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n        \n    train_dataset = TrainDataset(folds.loc[trn_idx].reset_index(drop=True), \n                                 folds.loc[trn_idx].reset_index(drop=True)[CFG.target_col], \n                                 transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(folds.loc[val_idx].reset_index(drop=True), \n                                 folds.loc[val_idx].reset_index(drop=True)[CFG.target_col], \n                                 transform=get_transforms(data='valid'))\n    \n    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=4)\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4)\n    \n    #Figure out how to train pretrained model\n    model = ViTBase16(n_classes=1, pretrained=True)\n    model.to(device)\n    \n    optimizer = Adam(model.parameters(), lr=CFG.lr, amsgrad=False)\n    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n    \n    criterion = nn.MSELoss()\n    #criterion = nn.BCEWithLogitsLoss()\n    best_score = -100\n    best_loss = np.inf\n    best_preds = None\n    \n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n\n        model.train()\n        avg_loss = 0.\n\n        optimizer.zero_grad()\n        tk0 = tqdm(enumerate(train_loader), total=len(train_loader),position=0,leave=True)\n\n        for i, (images, labels) in tk0:\n\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            y_preds = model(images)\n            loss = criterion(y_preds.view(-1), labels)\n            \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            avg_loss += loss.item() / len(train_loader)\n            \n        model.eval()\n        avg_val_loss = 0.\n        preds = []\n        valid_labels = []\n        tk1 = tqdm(enumerate(valid_loader), total=len(valid_loader),position=0,leave=True)\n\n        for i, (images, labels) in tk1:\n            \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            with torch.no_grad():\n                y_preds = model(images)\n            \n            preds.append(y_preds.to('cpu').numpy())\n            valid_labels.append(labels.to('cpu').numpy())\n\n            loss = criterion(y_preds.view(-1), labels)\n            avg_val_loss += loss.item() / len(valid_loader)\n        \n        scheduler.step(avg_val_loss)\n            \n        preds = np.concatenate(preds)\n        valid_labels = np.concatenate(valid_labels)\n        \n        optimized_rounder.fit(preds, valid_labels)\n        coefficients = optimized_rounder.coefficients()\n        final_preds = optimized_rounder.predict(preds, coefficients)\n        LOGGER.debug(f'Counter preds: {Counter(np.concatenate(final_preds))}')\n        LOGGER.debug(f'coefficients: {coefficients}')\n        score = quadratic_weighted_kappa(valid_labels, final_preds)\n\n        elapsed = time.time() - start_time\n        \n        LOGGER.debug(f'  Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.debug(f'  Epoch {epoch+1} - QWK: {score}  coefficients: {coefficients}')\n        \n        if score>best_score:\n            best_score = score\n            best_preds = preds\n            LOGGER.debug(f'  Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model  coefficients: {coefficients}')\n            torch.save(model.state_dict(), f'fold{fold}_se_resnext50.pth')\n    \n    return best_preds, valid_labels","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:43.953907Z","iopub.execute_input":"2023-05-25T10:24:43.954525Z","iopub.status.idle":"2023-05-25T10:24:43.983990Z","shell.execute_reply.started":"2023-05-25T10:24:43.954473Z","shell.execute_reply":"2023-05-25T10:24:43.983066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nvalid_labels = []\nfor fold in range(CFG.n_fold):\n    _preds, _valid_labels = train_fn(fold)\n    preds.append(_preds)\n    valid_labels.append(_valid_labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:24:43.985394Z","iopub.execute_input":"2023-05-25T10:24:43.985967Z","iopub.status.idle":"2023-05-25T10:35:11.448652Z","shell.execute_reply.started":"2023-05-25T10:24:43.985735Z","shell.execute_reply":"2023-05-25T10:35:11.444656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CV\npreds = np.concatenate(preds)\nvalid_labels = np.concatenate(valid_labels)\n\noptimized_rounder = OptimizedRounder()\noptimized_rounder.fit(preds, valid_labels)\ncoefficients = optimized_rounder.coefficients()\nfinal_preds = optimized_rounder.predict(preds, coefficients)\nLOGGER.debug(f'Counter preds: {Counter(np.concatenate(final_preds))}')\nLOGGER.debug(f'coefficients: {coefficients}')\n\nscore = quadratic_weighted_kappa(valid_labels, final_preds)\nLOGGER.debug(f'CV QWK: {score}')","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:35:11.451102Z","iopub.status.idle":"2023-05-25T10:35:11.451661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"def inference(model, test_loader, device):\n    \n    model.to(device) \n    \n    probs = []\n\n    for i, images in enumerate(test_loader):\n            \n        images = images.to(device)\n            \n        with torch.no_grad():\n            y_preds = model(images)\n            \n        probs.append(y_preds.to('cpu').numpy())\n\n    probs = np.concatenate(probs)\n    \n    return probs","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:35:11.453223Z","iopub.status.idle":"2023-05-25T10:35:11.455040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submit(sample, coefficients, dir_name='test_images'):\n    if os.path.exists(f'../input/prostate-cancer-grade-assessment/{dir_name}'):\n        print('run inference')\n        test_dataset = TestDataset(sample, dir_name, transform=get_transforms(data='valid'))\n        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)\n        probs = []\n        for fold in range(CFG.n_fold):\n            model = ViTBase16(n_classes=1, pretrained=False)\n            weights_path = f'fold{fold}_se_resnext50.pth'\n            #weights_path = f'fold0_se_resnext50.pth'\n            model.load_state_dict(torch.load(weights_path, map_location=device))\n            _probs = inference(model, test_loader, device)\n            probs.append(_probs)\n        probs = np.mean(probs, axis=0)\n        optimized_rounder = OptimizedRounder()\n        preds = optimized_rounder.predict(probs, coefficients)\n        sample['isup_grade'] = preds\n    return sample","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:35:11.456382Z","iopub.status.idle":"2023-05-25T10:35:11.457293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check using train_images\nsubmission = submit(train.head(), coefficients, dir_name='train_images')\nsubmission['isup_grade'] = submission['isup_grade'].astype(int)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:35:11.458626Z","iopub.status.idle":"2023-05-25T10:35:11.459514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test submission\nsubmission = submit(sample, coefficients, dir_name='test_images')\nsubmission['isup_grade'] = submission['isup_grade'].astype(int)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T10:35:11.460893Z","iopub.status.idle":"2023-05-25T10:35:11.461791Z"},"trusted":true},"execution_count":null,"outputs":[]}]}